/**
 * ğŸŒ  éŠ€æ²³æ‰‹å¯«æ•¸å­—è¾¨è­˜ç³»çµ± - æ·±åº¦æ¶æ§‹ä¿®å¾©ç‰ˆ
 * ---------------------------------------------------------
 * é‡å° image_794f42.png ä¸­çš„ "Provided weight data has no target variable" é€²è¡Œä¿®å¾©
 * 1. å¼·åˆ¶ä¿®å¾© Sequential å‘½åç©ºé–“
 * 2. æ‰‹å‹•æ³¨å…¥ InputLayer Shape
 * 3. å®Œæ•´ç§»æ¤ p.py çš„ cv2.dilate èˆ‡ cv2.moments
 */

// ==========================================
// 1. å…¨åŸŸå…ƒä»¶èˆ‡è®Šæ•¸
// ==========================================
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d', { willReadFrequently: true });
const video = document.getElementById('camera-feed');
const mainBox = document.getElementById('mainBox');
const camToggleBtn = document.getElementById('camToggleBtn');
const eraserBtn = document.getElementById('eraserBtn');
const fileInput = document.getElementById('fileInput');
const digitDisplay = document.getElementById('digit-display');
const confDetails = document.getElementById('conf-details');
const voiceBtn = document.getElementById('voiceBtn');

let model = null;
let isDrawing = false;
let isEraser = false;
let cameraStream = null;
let realtimeInterval = null;
let recognition = null;
let isVoiceActive = false;

// éŠ€æ²³è¦–è¦ºèˆ‡é‹ç®—åƒæ•¸ (å°æ¨™ p.py)
const PEN_WIDTH = 18;
const ERASER_WIDTH = 60;
const GALAXY_COLORS = ["#a3d9ff", "#7ed6df", "#e056fd", "#686de0", "#ffffff"];
const MNIST_PAD = 0.45; // ä¾ç…§ p.py è¨­å®š 45% é‚Šç•Œå¡«å……

// ==========================================
// 2. æ ¸å¿ƒï¼šæ¨¡å‹è¼‰å…¥å™¨èˆ‡æ¬Šé‡å‘½åä¿®å¾© (è§£æ±ºæˆªåœ–ä¸­çš„å ±éŒ¯)
// ==========================================

async function loadModelAndFix() {
    const modelUrl = `tfjs_model/model.json?nocache=${Date.now()}`;
    
    try {
        confDetails.innerHTML = "<span class='loading'>ğŸ§¬ æ­£åœ¨æ””æˆªä¸¦ä¿®æ­£ç¥ç¶“ç¶²è·¯æ¶æ§‹...</span>";
        await tf.ready();

        // å»ºç«‹è‡ªå®šç¾©è¼‰å…¥è™•ç†å™¨ï¼Œæ‰‹å‹•ä¿®æ”¹ JSON å…§å®¹
        const handler = tf.io.browserHTTPRequest(modelUrl);
        const originalLoad = handler.load.bind(handler);

        handler.load = async () => {
            const artifacts = await originalLoad();
            
            console.log("ğŸ› ï¸ åŸå§‹æ¬Šé‡æ¸…å–®:", artifacts.weightSpecs.map(s => s.name));

            // [ä¿®å¾© 1] è§£æ±º "An InputLayer should be passed an inputShape" éŒ¯èª¤
            if (artifacts.modelTopology && artifacts.modelTopology.model_config) {
                const config = artifacts.modelTopology.model_config.config;
                const layers = Array.isArray(config) ? config : config.layers;
                
                layers.forEach(layer => {
                    if (layer.class_name === 'InputLayer' || layer.config.name === 'conv2d_input') {
                        if (!layer.config.batch_input_shape) {
                            layer.config.batch_input_shape = [null, 28, 28, 1];
                        }
                    }
                });
            }

            // [ä¿®å¾© 2] è§£æ±º "weight data has no target variable" éŒ¯èª¤
            // æˆªåœ–é¡¯ç¤ºå ±éŒ¯å°‹æ‰¾ sequential/conv2d/kernelï¼Œæ‰€ä»¥æˆ‘å€‘å¿…é ˆç§»é™¤æ¬Šé‡æ¸…å–®ä¸­çš„ sequential å‰ç¶´
            if (artifacts.weightSpecs) {
                artifacts.weightSpecs.forEach(spec => {
                    // å°‡ "sequential/conv2d/kernel" è½‰ç‚º "conv2d/kernel"
                    const oldName = spec.name;
                    spec.name = spec.name.replace(/^sequential(\/|_\d+\/)/, '');
                    if (oldName !== spec.name) {
                        console.log(`âœ… æ¬Šé‡è¦–å°„ä¿®è£œ: ${oldName} -> ${spec.name}`);
                    }
                });
            }

            return artifacts;
        };

        model = await tf.loadLayersModel(handler);
        confDetails.innerText = "ğŸš€ éŠ€æ²³æ ¸å¿ƒåŒæ­¥æˆåŠŸï¼Œæ¨¡å‹å·²å°±ç·’";
        
        // é ç†±å¼µé‡é‹ç®—
        tf.tidy(() => model.predict(tf.zeros([1, 28, 28, 1])));
    } catch (err) {
        console.error("è¼‰å…¥å¤±æ•—è©³æƒ…:", err);
        confDetails.innerHTML = `<span style="color:#ff4757">âŒ è¼‰å…¥å¤±æ•—: ${err.message}</span>`;
    }
}

// ==========================================
// 3. åº•å±¤å½±åƒé‚è¼¯ (å®Œå…¨ç§»æ¤ p.py çš„ OpenCV æ¼”ç®—æ³•)
// ==========================================

/**
 * æ‰‹å¯«å¯¦ä½œ cv2.dilate (è†¨è„¹)
 * è§£æ±ºæ‰‹å¯«ç·šæ¢å¤ªç´°åœ¨ç¸®æ”¾å¾Œå¤±çœŸçš„å•é¡Œ
 */
function manualDilate(pixelData, width, height) {
    const output = new Uint8ClampedArray(pixelData.length);
    for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
            let max = 0;
            // 3x3 æ ¸å¿ƒ
            for (let ky = -1; ky <= 1; ky++) {
                for (let kx = -1; kx <= 1; kx++) {
                    const ny = y + ky, nx = x + kx;
                    if (ny >= 0 && ny < height && nx >= 0 && nx < width) {
                        max = Math.max(max, pixelData[ny * width + nx]);
                    }
                }
            }
            output[y * width + x] = max;
        }
    }
    return output;
}

/**
 * æ‰‹å¯«å¯¦ä½œ cv2.moments (è³ªå¿ƒåç§»)
 * é€™æ˜¯ p.py èƒ½ç²¾ç¢ºè¾¨è­˜é‚Šè§’æ•¸å­—çš„æ ¸å¿ƒ
 */
function getShiftVector(pixels, w, h) {
    let m00 = 0, m10 = 0, m01 = 0;
    for (let y = 0; y < h; y++) {
        for (let x = 0; x < w; x++) {
            const v = pixels[y * w + x];
            if (v > 10) {
                m00 += v; m10 += x * v; m01 += y * v;
            }
        }
    }
    if (m00 === 0) return { dx: 0, dy: 0 };
    return { dx: (w / 2) - (m10 / m00), dy: (h / 2) - (m01 / m00) };
}

/**
 * è™•ç†å–®ä¸€æ•¸å­— ROI (å°æ¨™ p.py çš„ resize èˆ‡ centering)
 */
async function processDigitROI(roiCanvas) {
    const tempCtx = roiCanvas.getContext('2d');
    const raw = tempCtx.getImageData(0, 0, roiCanvas.width, roiCanvas.height);
    
    // 1. è½‰ç°éšä¸¦æ‡‰ç”¨äºŒå€¼åŒ– (Threshold)
    let gray = new Uint8ClampedArray(raw.width * raw.height);
    for (let i = 0; i < raw.data.length; i += 4) {
        gray[i / 4] = raw.data[i] > 120 ? 255 : 0;
    }

    // 2. è†¨è„¹è™•ç† (Dilate)
    gray = manualDilate(gray, raw.width, raw.height);

    // 3. è¨ˆç®—è³ªå¿ƒä½ç§»
    const shift = getShiftVector(gray, raw.width, raw.height);

    // 4. å»ºç«‹ 28x28 ç•«å¸ƒä¸¦é€²è¡Œå°é½Š (å¦‚åŒ p.py çš„ä¸­å¿ƒæ ¡æ­£)
    const final = document.createElement('canvas');
    final.width = 28; final.height = 28;
    const fCtx = final.getContext('2d');
    fCtx.fillStyle = "black";
    fCtx.fillRect(0, 0, 28, 28);

    // å¥—ç”¨ p.py çš„ 45% Padding é‚è¼¯é€²è¡Œç¸®æ”¾ç¹ªè£½
    const side = Math.max(roiCanvas.width, roiCanvas.height);
    const scale = (28 * (1 - MNIST_PAD)) / side;
    
    fCtx.save();
    fCtx.translate(14 + shift.dx * scale, 14 + shift.dy * scale);
    fCtx.scale(scale, scale);
    fCtx.drawImage(roiCanvas, -roiCanvas.width / 2, -roiCanvas.height / 2);
    fCtx.restore();

    // 5. è½‰ç‚ºå¼µé‡é æ¸¬
    const tensor = tf.tidy(() => {
        return tf.browser.fromPixels(final, 1).toFloat().div(255.0).expandDims(0);
    });

    const pred = model.predict(tensor);
    const scores = await pred.data();
    const result = {
        digit: pred.argMax(-1).dataSync()[0],
        conf: Math.max(...scores)
    };

    tf.dispose([tensor, pred]);
    return result;
}

// ==========================================
// 4. å€åŸŸåµæ¸¬èˆ‡å¤šä½æ•¸æƒæ (CCA æ¼”ç®—æ³•)
// ==========================================

function findDigitRegions(ctx, isRealtime) {
    const imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const { data, width, height } = imgData;
    const visited = new Uint8Array(width * height);
    const regions = [];
    const step = isRealtime ? 4 : 2;

    for (let y = 0; y < height; y += step) {
        for (let x = 0; x < width; x += step) {
            const i = y * width + x;
            if (!visited[i] && data[i * 4] > 100) {
                let stack = [[x, y]];
                visited[i] = 1;
                let minX = x, maxX = x, minY = y, maxY = y, pixels = 0;

                while (stack.length > 0) {
                    const [cx, cy] = stack.pop();
                    pixels++;
                    minX = Math.min(minX, cx); maxX = Math.max(maxX, cx);
                    minY = Math.min(minY, cy); maxY = Math.max(maxY, cy);

                    [[cx+step, cy], [cx-step, cy], [cx, cy+step], [cx, cy-step]].forEach(([nx, ny]) => {
                        if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                            const ni = ny * width + nx;
                            if (!visited[ni] && data[ni * 4] > 100) {
                                visited[ni] = 1; stack.push([nx, ny]);
                            }
                        }
                    });
                }

                const w = maxX - minX + 1;
                const h = maxY - minY + 1;
                // p.py éæ¿¾é›œè¨Šèˆ‡æ¯”ä¾‹
                if (pixels * (step**2) < 200) continue;
                if (w / h > 2.5 || h / w > 3.2) continue;
                regions.push({ x: minX, y: minY, w, h });
            }
        }
    }
    return regions.sort((a, b) => a.x - b.x);
}

// ==========================================
// 5. è¾¨è­˜åŸ·è¡Œèˆ‡ UI æ§åˆ¶
// ==========================================

async function runRecognition(isRealtime = false) {
    if (!model) return;

    const snap = document.createElement('canvas');
    snap.width = canvas.width; snap.height = canvas.height;
    const sCtx = snap.getContext('2d');
    if (cameraStream) sCtx.drawImage(video, 0, 0, canvas.width, canvas.height);
    sCtx.drawImage(canvas, 0, 0);

    const regions = findDigitRegions(sCtx, isRealtime);
    let finalStr = "";
    let logHtml = "";

    if (isRealtime) ctx.clearRect(0, 0, canvas.width, canvas.height);

    for (let i = 0; i < regions.length; i++) {
        const r = regions[i];
        const roi = document.createElement('canvas');
        roi.width = r.w; roi.height = r.h;
        roi.getContext('2d').putImageData(sCtx.getImageData(r.x, r.y, r.w, r.h), 0, 0);

        // é€£é«”å­—åˆ‡å‰² (p.py: width > height * 1.3)
        if (r.w > r.h * 1.35) {
            const mid = r.w / 2;
            const subs = [{ x: 0, w: mid }, { x: mid, w: r.w - mid }];
            for (const sub of subs) {
                const subC = document.createElement('canvas');
                subC.width = sub.w; subC.height = r.h;
                subC.getContext('2d').drawImage(roi, sub.x, 0, sub.w, r.h, 0, 0, sub.w, r.h);
                const res = await processDigitROI(subC);
                if (res.conf > 0.8) {
                    finalStr += res.digit;
                    logHtml += `å€åŸŸ ${i}S: <span class="highlight">${res.digit}</span> (${(res.conf*100).toFixed(1)}%)<br>`;
                }
            }
        } else {
            const res = await processDigitROI(roi);
            if (res.conf >= (isRealtime ? 0.9 : 0.7)) {
                finalStr += res.digit;
                logHtml += `å€åŸŸ ${i+1}: <span class="highlight">${res.digit}</span> (${(res.conf*100).toFixed(1)}%)<br>`;
                if (isRealtime) drawFocusBox(r, res.digit);
            }
        }
    }

    digitDisplay.innerText = finalStr || "---";
    confDetails.innerHTML = logHtml;
    if (isRealtime) updatePen();
}

function drawFocusBox(r, digit) {
    ctx.strokeStyle = "#00FF00";
    ctx.lineWidth = 3;
    ctx.strokeRect(r.x, r.y, r.w, r.h);
    ctx.fillStyle = "#00FF00";
    ctx.font = "bold 20px Orbitron";
    ctx.fillText(digit, r.x, r.y - 8);
}

// ==========================================
// 6. éŠ€æ²³æ•ˆæœèˆ‡äº¤äº’ç³»çµ± (å°æ¨™ä½ åŸæœ¬çš„ JS)
// ==========================================

function spawnGalaxyEffect(x, y) {
    const star = document.createElement('div');
    star.className = "star-particle";
    const color = GALAXY_COLORS[Math.floor(Math.random() * GALAXY_COLORS.length)];
    star.style.cssText = `
        position: absolute; left: ${x}px; top: ${y}px;
        width: 5px; height: 5px; background: ${color};
        box-shadow: 0 0 12px ${color}; border-radius: 50%;
        pointer-events: none; animation: star-fade 0.8s forwards;
    `;
    document.body.appendChild(star);
    setTimeout(() => star.remove(), 800);
}

function clearUniverse() {
    ctx.fillStyle = "black";
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    digitDisplay.innerText = "---";
    confDetails.innerText = "æ˜ŸåŸŸå·²å›æ­¸è™›ç„¡";
    addNebula(20);
}

function addNebula(n) {
    for (let i = 0; i < n; i++) {
        ctx.fillStyle = `rgba(255, 255, 255, ${Math.random() * 0.2})`;
        ctx.beginPath();
        ctx.arc(Math.random()*canvas.width, Math.random()*canvas.height, Math.random()*2, 0, Math.PI*2);
        ctx.fill();
    }
}

async function toggleCam() {
    if (cameraStream) {
        cameraStream.getTracks().forEach(t => t.stop());
        cameraStream = null;
        clearInterval(realtimeInterval);
        video.style.display = "none";
        mainBox.classList.remove('cam-active');
        camToggleBtn.innerHTML = "ğŸ“· é–‹å•Ÿé¡é ­";
        clearUniverse();
    } else {
        try {
            cameraStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
            video.srcObject = cameraStream;
            video.style.display = "block";
            mainBox.classList.add('cam-active');
            camToggleBtn.innerHTML = "ğŸ“· é—œé–‰é¡é ­";
            realtimeInterval = setInterval(() => runRecognition(true), 500);
        } catch (e) { alert("é¡é ­åˆå§‹åŒ–å¤±æ•—"); }
    }
}

// [åŸºç¤ç¹ªåœ–é‚è¼¯]
function updatePen() {
    ctx.lineCap = 'round'; ctx.lineJoin = 'round';
    ctx.strokeStyle = isEraser ? "black" : "white";
    ctx.lineWidth = isEraser ? ERASER_WIDTH : PEN_WIDTH;
}

function getCoord(e) {
    const r = canvas.getBoundingClientRect();
    const x = (e.touches ? e.touches[0].clientX : e.clientX) - r.left;
    const y = (e.touches ? e.touches[0].clientY : e.clientY) - r.top;
    return { x, y };
}

canvas.addEventListener('mousedown', (e) => {
    isDrawing = true; ctx.beginPath();
    const p = getCoord(e); ctx.moveTo(p.x, p.y);
});

canvas.addEventListener('mousemove', (e) => {
    if (!isDrawing) return;
    const p = getCoord(e);
    ctx.lineTo(p.x, p.y); ctx.stroke();
    ctx.beginPath(); ctx.moveTo(p.x, p.y);
    if (!isEraser) spawnGalaxyEffect(p.x + window.scrollX, p.y + window.scrollY);
});

const endDraw = () => { if (isDrawing) { isDrawing = false; if (!cameraStream) runRecognition(false); } };
canvas.addEventListener('mouseup', endDraw);
canvas.addEventListener('mouseleave', endDraw);
canvas.addEventListener('touchstart', (e) => { e.preventDefault(); isDrawing = true; ctx.beginPath(); const p = getCoord(e); ctx.moveTo(p.x, p.y); });
canvas.addEventListener('touchmove', (e) => { e.preventDefault(); if(isDrawing) { const p = getCoord(e); ctx.lineTo(p.x, p.y); ctx.stroke(); ctx.beginPath(); ctx.moveTo(p.x, p.y); } });
canvas.addEventListener('touchend', endDraw);

function toggleEraser() {
    isEraser = !isEraser;
    eraserBtn.innerText = isEraser ? "ç•«ç­†æ¨¡å¼" : "æ©¡çš®æ“¦æ¨¡å¼";
    updatePen();
}

function handleUpload(e) {
    const reader = new FileReader();
    reader.onload = (ev) => {
        const img = new Image();
        img.onload = () => {
            clearUniverse();
            const s = Math.min(canvas.width/img.width, canvas.height/img.height) * 0.8;
            ctx.drawImage(img, (canvas.width-img.width*s)/2, (canvas.height-img.height*s)/2, img.width*s, img.height*s);
            runRecognition(false);
        };
        img.src = ev.target.result;
    };
    reader.readAsDataURL(e.target.files[0]);
}

// å•Ÿå‹•ç³»çµ±
loadModelAndFix();
clearUniverse();
