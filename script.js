/**
 * ğŸŒŒ éŠ€æ²³æ‰‹å¯«æ•¸å­—è¾¨è­˜ç³»çµ± - çµ‚æ¥µå…¨åŠŸèƒ½æ•´åˆç‰ˆ
 * æ•´åˆï¼šæ¨¡å‹ä¿®å¾©ã€èªéŸ³æ§åˆ¶ã€æª”æ¡ˆä¸Šå‚³ã€éŠ€æ²³ç‰¹æ•ˆã€å³æ™‚é¡é ­ã€é€²éšåˆ†å‰²
 */

// --- 1. å¸¸æ•¸èˆ‡å…¨åŸŸè®Šæ•¸ ---
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d', { willReadFrequently: true });
const video = document.getElementById('camera-feed');
const mainBox = document.getElementById('mainBox');
const camToggleBtn = document.getElementById('camToggleBtn');
const eraserBtn = document.getElementById('eraserBtn');
const fileInput = document.getElementById('fileInput');
const digitDisplay = document.getElementById('digit-display');
const confDetails = document.getElementById('conf-details');

const voiceBtn = document.getElementById('voiceBtn');
const voiceStatus = document.getElementById('voice-status');

let model = null;
let isDrawing = false;
let isEraser = false;
let cameraStream = null;
let realtimeInterval = null;
let recognition = null;
let isVoiceActive = false;

// --- ğŸ› ï¸ è¶…ç´šä¿®å¾©è¼‰å…¥å™¨ (Super Patch Loader) ---
// é‡å° TensorFlow.js èˆ‡ Keras 3.x è½‰æ›å¾Œçš„ç›¸å®¹æ€§ä¿®è£œ
class PatchModelLoader {
    constructor(url) { this.url = url; }
    
    async load() {
        const loader = tf.io.browserHTTPRequest(this.url);
        const artifacts = await loader.load();
        
        console.log("ğŸ› ï¸ æ­£åœ¨åŸ·è¡Œæ·±åº¦ä¿®å¾©...");

        // ä¿®å¾© A: æ³¨å…¥ InputLayer å½¢ç‹€
        const traverseAndPatch = (obj) => {
            if (!obj || typeof obj !== 'object') return;
            if (obj.class_name === 'InputLayer' && obj.config) {
                const cfg = obj.config;
                if (!cfg.batchInputShape && !cfg.batch_input_shape) {
                    console.log(`ğŸ”§ [ä¿®å¾© A] æ³¨å…¥å½¢ç‹€ [null, 28, 28, 1]`);
                    cfg.batchInputShape = [null, 28, 28, 1];
                }
            }
            if (Array.isArray(obj)) obj.forEach(item => traverseAndPatch(item));
            else Object.keys(obj).forEach(key => traverseAndPatch(obj[key]));
        };
        if (artifacts.modelTopology) traverseAndPatch(artifacts.modelTopology);

        // ä¿®å¾© B: ä¿®æ­£æ¬Šé‡åç¨± (ç§»é™¤ sequential/ å‰ç¶´)
        if (artifacts.weightSpecs) {
            artifacts.weightSpecs.forEach(spec => {
                if (spec.name.includes('sequential/')) {
                    spec.name = spec.name.replace('sequential/', '');
                }
            });
        }
        return artifacts;
    }
}

// --- 2. ç³»çµ±åˆå§‹åŒ– ---
async function init() {
    ctx.fillStyle = "black";
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    updatePen();
    initSpeechRecognition();
    addGalaxyEffects();

    const modelUrl = `tfjs_model/model.json?t=${Date.now()}`;

    try {
        confDetails.innerText = "ğŸŒŒ æ­£åœ¨å•Ÿå‹•éŠ€æ²³ AI å¼•æ“...";
        await tf.setBackend('cpu');
        await tf.ready();

        model = await tf.loadLayersModel(new PatchModelLoader(modelUrl));
        
        console.log("âœ… ç³»çµ±å…¨ç·šå°±ç·’ï¼");
        confDetails.innerText = "ğŸš€ ç³»çµ±å°±ç·’ï¼Œè«‹é–‹å§‹åœ¨æ˜ŸåŸŸæ›¸å¯«";
        
        // æš–èº«é æ¸¬
        tf.tidy(() => model.predict(tf.zeros([1, 28, 28, 1])));
    } catch (err) {
        console.error("åˆå§‹åŒ–å¤±æ•—:", err);
        confDetails.innerHTML = `<span style="color:red">âŒ è¼‰å…¥å¤±æ•—: ${err.message}</span>`;
    }
}

// --- 3. æ ¸å¿ƒè¾¨è­˜èˆ‡å½±åƒè™•ç† ---
function advancedPreprocess(roiCanvas) {
    return tf.tidy(() => {
        let tensor = tf.browser.fromPixels(roiCanvas, 1);
        tensor = tensor.toFloat().div(tf.scalar(255.0));
        tensor = tf.image.resizeBilinear(tensor, [28, 28]);
        return tensor.expandDims(0);
    });
}

async function predict() {
    if (!model) return;

    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const boxes = findDigitBoxes(imageData);
    
    let finalRes = "";
    let details = [];
    let validBoxes = [];

    for (let box of boxes) {
        const { x, y, w, h, area } = box;
        const MIN_AREA = cameraStream ? 500 : 150;
        if (area < MIN_AREA) continue;
        
        const aspectRatio = w / h;
        if (aspectRatio > 2.5 || aspectRatio < 0.15) continue;

        const roiCanvas = document.createElement('canvas');
        roiCanvas.width = w; roiCanvas.height = h;
        const roiCtx = roiCanvas.getContext('2d');
        roiCtx.drawImage(canvas, x, y, w, h, 0, 0, w, h);

        // --- é€²éšé‚è¼¯ï¼šåˆ†å‰²å¯¬åº¦éå¤§çš„é€£å­— (å¦‚ 11) ---
        if (w > h * 1.3) {
            const splitX = Math.floor(w / 2);
            const widths = [splitX, w - splitX];
            const offsets = [0, splitX];

            for (let i = 0; i < 2; i++) {
                const subCanvas = document.createElement('canvas');
                subCanvas.width = widths[i]; subCanvas.height = h;
                subCanvas.getContext('2d').drawImage(roiCanvas, offsets[i], 0, widths[i], h, 0, 0, widths[i], h);
                
                const input = advancedPreprocess(subCanvas);
                const pred = model.predict(input);
                const score = await pred.data();
                const digit = pred.argMax(-1).dataSync()[0];
                const conf = Math.max(...score);

                if (conf > 0.8) {
                    finalRes += digit.toString();
                    details.push({ digit, conf: (conf * 100).toFixed(1) + "%" });
                }
                input.dispose(); pred.dispose();
            }
            continue;
        }

        // ä¸€èˆ¬è¾¨è­˜
        const input = advancedPreprocess(roiCanvas);
        const pred = model.predict(input);
        const score = await pred.data();
        const digit = pred.argMax(-1).dataSync()[0];
        const conf = Math.max(...score);

        if (conf > 0.85) {
            finalRes += digit.toString();
            details.push({ digit, conf: (conf * 100).toFixed(1) + "%" });
            validBoxes.push(box);
        }
        input.dispose(); pred.dispose();
    }

    digitDisplay.innerText = finalRes || "---";
    updateDetails(details);

    if (cameraStream) {
        // åœ¨é¡é ­æ¨¡å¼ä¸‹ç¹ªè£½ç¶ è‰²åµæ¸¬æ¡†
        validBoxes.forEach((box, i) => {
            ctx.strokeStyle = "#00FF00";
            ctx.lineWidth = 3;
            ctx.strokeRect(box.x, box.y, box.w, box.h);
        });
    }
}

// é€£é€šåŸŸç®—æ³•ï¼šæ‰¾å°‹ç¨ç«‹æ•¸å­—
function findDigitBoxes(imageData) {
    const { data, width, height } = imageData;
    const visited = new Uint8Array(width * height);
    const boxes = [];

    for (let y = 0; y < height; y += 5) {
        for (let x = 0; x < width; x += 5) {
            const idx = y * width + x;
            if (!visited[idx] && data[idx * 4] > 100) {
                let minX = x, maxX = x, minY = y, maxY = y, count = 0;
                let queue = [[x, y]];
                visited[idx] = 1;

                while (queue.length > 0) {
                    const [cx, cy] = queue.shift();
                    count++;
                    minX = Math.min(minX, cx); maxX = Math.max(maxX, cx);
                    minY = Math.min(minY, cy); maxY = Math.max(maxY, cy);
                    [[cx+10, cy], [cx-10, cy], [cx, cy+10], [cx, cy-10]].forEach(([nx, ny]) => {
                        if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                            const nIdx = ny * width + nx;
                            if (!visited[nIdx] && data[nIdx * 4] > 100) {
                                visited[nIdx] = 1; queue.push([nx, ny]);
                            }
                        }
                    });
                }
                boxes.push({ x: minX, y: minY, w: maxX - minX + 1, h: maxY - minY + 1, area: count * 25 });
            }
        }
    }
    return boxes.sort((a, b) => a.x - b.x);
}

// --- 4. UI è¦–è¦ºèˆ‡äº’å‹•åŠŸèƒ½ ---
function addGalaxyEffects() {
    // å¢åŠ ä¸€äº›é»ç¶´æ˜Ÿå…‰
    ctx.fillStyle = "rgba(163, 217, 255, 0.3)";
    ctx.beginPath(); ctx.arc(600, 50, 2, 0, Math.PI * 2); ctx.fill();
    ctx.beginPath(); ctx.arc(50, 350, 1.5, 0, Math.PI * 2); ctx.fill();
}

function updatePen() {
    ctx.lineCap = 'round'; ctx.lineJoin = 'round';
    if (isEraser) { ctx.strokeStyle = "black"; ctx.lineWidth = 40; }
    else { ctx.strokeStyle = "white"; ctx.lineWidth = 15; }
}

function toggleEraser() {
    isEraser = !isEraser;
    eraserBtn.innerText = isEraser ? "æ©¡çš®æ“¦ï¼šé–‹å•Ÿ" : "æ©¡çš®æ“¦ï¼šé—œé–‰";
    eraserBtn.classList.toggle('eraser-active', isEraser);
    updatePen();
}

function clearCanvas() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.fillStyle = "black"; ctx.fillRect(0, 0, canvas.width, canvas.height);
    digitDisplay.innerText = "---";
    addGalaxyEffects();
}

async function toggleCamera() {
    if (cameraStream) {
        cameraStream.getTracks().forEach(t => t.stop());
        cameraStream = null;
        video.style.display = "none";
        camToggleBtn.innerText = "ğŸ“· é–‹å•Ÿé¡é ­";
        clearInterval(realtimeInterval);
        init(); 
    } else {
        try {
            cameraStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
            video.srcObject = cameraStream;
            video.style.display = "block";
            camToggleBtn.innerText = "ğŸ“· é—œé–‰é¡é ­";
            realtimeInterval = setInterval(() => predict(), 500);
        } catch (err) { alert("é¡é ­æ•…éšœ: " + err); }
    }
}

// èªéŸ³è¾¨è­˜åˆå§‹åŒ–
function initSpeechRecognition() {
    const Speech = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!Speech) return;
    recognition = new Speech();
    recognition.lang = 'zh-TW';
    recognition.onresult = (e) => {
        const text = e.results[0][0].transcript;
        if (text.includes('æ¸…é™¤')) clearCanvas();
    };
}

function toggleVoice() {
    if (!recognition) return;
    if (isVoiceActive) recognition.stop(); else recognition.start();
    isVoiceActive = !isVoiceActive;
    voiceBtn.classList.toggle('voice-active', isVoiceActive);
}

// æª”æ¡ˆä¸Šå‚³
function triggerFile() { fileInput.click(); }
function handleFile(e) {
    const file = e.target.files[0];
    const reader = new FileReader();
    reader.onload = (event) => {
        const img = new Image();
        img.onload = () => {
            clearCanvas();
            ctx.drawImage(img, 50, 50, canvas.width-100, canvas.height-100);
            predict();
        };
        img.src = event.target.result;
    };
    reader.readAsDataURL(file);
}

function updateDetails(data) {
    let html = "<b>è©³ç´°è¾¨è­˜è³‡è¨Šï¼š</b><br>";
    if (data.length === 0) html += "ç­‰å¾…è¼¸å…¥...";
    else data.forEach((item, i) => {
        html += `æ•¸å­— ${i+1}: <b style="color:#a3d9ff">${item.digit}</b> (${item.conf})<br>`;
    });
    confDetails.innerHTML = html;
}

// --- 5. äº‹ä»¶ç›£è½ ---
function getPos(e) {
    const rect = canvas.getBoundingClientRect();
    const x = (e.touches ? e.touches[0].clientX : e.clientX) - rect.left;
    const y = (e.touches ? e.touches[0].clientY : e.clientY) - rect.top;
    return { x, y };
}

canvas.addEventListener('mousedown', (e) => { isDrawing = true; const p = getPos(e); ctx.beginPath(); ctx.moveTo(p.x, p.y); });
canvas.addEventListener('mousemove', (e) => { if (!isDrawing) return; const p = getPos(e); ctx.lineTo(p.x, p.y); ctx.stroke(); });
canvas.addEventListener('mouseup', () => { isDrawing = false; predict(); });
canvas.addEventListener('touchstart', (e) => { e.preventDefault(); isDrawing = true; const p = getPos(e); ctx.beginPath(); ctx.moveTo(p.x, p.y); });
canvas.addEventListener('touchmove', (e) => { e.preventDefault(); if (!isDrawing) return; const p = getPos(e); ctx.lineTo(p.x, p.y); ctx.stroke(); });
canvas.addEventListener('touchend', () => { isDrawing = false; predict(); });

init();
